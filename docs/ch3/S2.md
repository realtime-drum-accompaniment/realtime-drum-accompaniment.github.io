---
title: S2 - Model Source and Checkpoint
permalink: /supplementary/2/
parent: Chapter 3 - Drum Loop Generation
nav_order: 2
layout: supplement_page
---
## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Source Code

<br>

The source code for the model is available at [https://github.com/behzadhaki/GrooveTransformer](https://github.com/behzadhaki/GrooveTransformer).

This repository holds all the training data, model source definitions, and trained checkpoints. 

Note that there are multiple models hosted here, but the one used in this chapter is located in [model/Base](https://github.com/behzadhaki/GrooveTransformer/tree/master/model/Base) directory.

A very detailed guide on how to use the models is available in the repository's [documentation](https://github.com/behzadhaki/GrooveTransformer/blob/main/documentation/chapter2_Model/A_MonotonicGrooveTransformer/README.md).

Below is a quick guide on loading the pretrained model checkpoints, and using them to generate drum loops.



---

## Downloading the Checkpoints

<br>

The checkpoints are available in the [model/Base/monotonic_groove_transformer_v1/latest](https://github.com/behzadhaki/GrooveTransformer/tree/main/model/Base/saved/monotonic_groove_transformer_v1/latest) directory.

{: .note }
> Each model also has a `.json` file that contains the model's configuration. This file is `NOT` required to load the model, but it is useful for understanding the model's architecture and hyperparameters.
> Moreover, the name of the models is different than the paper, with the json configurations, you can find the corresponding model. 
> Alternatively, use the following table to download the checkpoints directly.


| Model Name | Checkpoint Name | | 
|------------|------------------|---------------|
| Model 1 | rosie-durian-248 | [Download](https://github.com/behzadhaki/GrooveTransformer/raw/main/model/Base/saved/monotonic_groove_transformer_v1/latest/rosy_durian_248.pth){: .btn .btn-primary .fs-5 .mb-0 .mb-md-0 .mr-0 }|
| Model 2 | hopeful-gorge-252 | [Download](https://github.com/behzadhaki/GrooveTransformer/raw/main/model/Base/saved/monotonic_groove_transformer_v1/latest/hopeful_gorge_252.pth){: .btn .btn-primary .fs-5 .mb-0 .mb-md-0 .mr-0 } |
| Model 3 | solar-shadow-247 | [Download](https://github.com/behzadhaki/GrooveTransformer/raw/main/model/Base/saved/monotonic_groove_transformer_v1/latest/solar_shadow_247.pth){: .btn .btn-primary .fs-5 .mb-0 .mb-md-0 .mr-0 } |
| Model 4 | misunderstood-bush-246 | [Download](https://github.com/behzadhaki/GrooveTransformer/raw/main/model/Base/saved/monotonic_groove_transformer_v1/latest/misunderstood_bush_246.pth){: .btn .btn-primary .fs-5 .mb-0 .mb-md-0 .mr-0 } |


---

## Loading the Checkpoints
<br>

Each model contains a `.pth` file that can be loaded using the following code:

```python
from helpers.BasicMonotonicGrooveTransformer.modelLoadersSamplers import  load_mgt_model

model_path = "SomePathToTheModel.pth"
MonotonicGrooveTransformer = load_mgt_model(model_path)
```



---

## Generating Drum Loops

<br>

To generate drum loops, you can use the following code:

```python

from data import load_gmd_hvo_sequences

#   5.2 Pass groove to model and sample
from helpers import predict_using_mgt

voice_thresholds = [0.5] * 9    # Sampling threshold for each voice (kick, snare, chat, o hat, l tom, m tom, h tom, crash, ride)
voice_max_count_allowed = [32] * 9
input_groove_hvo = torch.rand((1, 32, 27))

output_hvo = predict_using_mgt(MonotonicGrooveTransformer, input_groove_hvo, voice_thresholds,
                            voice_max_count_allowed, return_concatenated=True)

output_hvo.shape
```




